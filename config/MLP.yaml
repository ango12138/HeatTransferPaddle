basic_config:
  root_path: './'
  data_name: 'dim_pro8_single_all.mat'
  training_size: 0.6
  batch_size: 32
  total_epoch: 800
  loss_name: 'mse'
  learning_rate: 1.e-3
  weight_decay: 0.
  learning_beta:
    - 0.7
    - 0.9
  learning_milestones:
    - 600
    - 700
    - 800
  learning_gamma: 0.1


MLP_model:
  in_dim: 10
  out_dim: 4
  steps: 1
  planes:
    - 64
    - 64
    - 64
    - 64
    - 64
  activation: 'gelu'
