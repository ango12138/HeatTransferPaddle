basic_config:
  root_path: './'
  data_name: 'dim_pro8_single_all.mat'
  training_size: 0.8
  batch_size: 64
  total_epoch: 200
  print_freq: 2
  save_freq: 40
  loss_name: 'mse'
  learning_rate: 1.e-3
  weight_decay: 0.
  learning_beta:
    - 0.9
    - 0.99
  learning_milestones:
    - 150
    - 200
  learning_gamma: 0.1

CNN_model:
  in_sizes: [396, 40, 10]
  out_sizes: [396, 40, 4]
  width: 32
  depth: 4
  steps: 1    # Number of steps to unroll, should be 1 in this problem
  activation: 'gelu'
  dropout: 0.0

FNO_model:
  in_dim: 10
  out_dim: 4
  modes: 12
  width: 32
  depth: 4
  steps: 1    # Number of steps to unroll, should be 1 in this problem
  padding: 0
  activation: 'gelu'
  dropout: 0.0

DON_model:
  in_dim: 2                # note: deeponet in_dim 为空间坐标
  out_dim: 4
  operator_dims:           # note: deeponet operator_dims 为设计变量
    - 10
  planes_branch:
    - 64
    - 64
    - 64
  planes_trunk:
    - 64
    - 64
    - 64
  activation: 'gelu'

MLP_model:
  in_dim: 10
  out_dim: 4
  steps: 1
  planes:
    - 64
    - 64
    - 64
  activation: 'gelu'

TNO_model:
  node_feats: 10
  pos_dim: 2
  n_targets: 4
  n_hidden: 64
  num_feat_layers: 0
  num_encoder_layers: 4
  n_head: 4
  normalizer: False
  dim_feedforward: 128
  residual_type: add
  attention_type: galerkin
  attn_activation: gelu
  feat_extract_type: None
  xavier_init: 0.01
  diagonal_weight: 0.01
  symmetric_init: False
  layer_norm: True
  attn_norm: False
  norm_eps: 0.00001
  batch_norm: False
  return_attn_weight: False
  return_latent: False
  decoder_type: ifft2
  last_activation: True
  freq_dim: 32
  num_regressor_layers: 2
  regressor_activation: gelu
  fourier_modes: 16
  spacial_dim: 2
  spacial_fc: False
  dropout: 0.0
  encoder_dropout: 0.0
  decoder_dropout: 0.0
  ffn_dropout: 0.0
