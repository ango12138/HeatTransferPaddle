general_config:
  root_path: './'
  total_epoch: 200
  loss_name: 'mse'
  learning_rate: 1.e-3
  weight_decay: 0.
  learning_beta:
    - 0.9
    - 0.999
  learning_milestones:
    - 100
    - 200
  learning_gamma: 0.1

CNN_model:
  in_sizes: [792, 40, 3]
  out_sizes: [792, 40, 3]
  width: 32
  depth: 4
  steps: 1    # Number of steps to unroll, should be 1 in this problem
  activation: 'gelu'
  dropout: 0.0

FNO_model:
  in_dim: 10
  out_dim: 4
  modes: 12
  width: 32
  depth: 4
  steps: 1    # Number of steps to unroll, should be 1 in this problem
  padding: 0
  activation: 'gelu'
  dropout: 0.0

DON_model:
  in_dim: 2
  out_dim: 3
  operator_dims:
    - 64
    - 64
    - 64
  planes_branch:
    - 64
    - 64
    - 64
  planes_trunk:
    - 64
    - 64
    - 64
  activation: 'gelu'

MLP_model:
  in_dim: 2
  out_dim: 4
  planes:
    - 64
    - 64
    - 64
  activation: 'gelu'

TNO_model:
  node_feats: 2
  pos_dim: 2
  n_targets: 3
  n_hidden: 64
  num_feat_layers: 0
  num_encoder_layers: 4
  n_head: 4
  normalizer: False
  dim_feedforward: 128
  residual_type: add
  attention_type: galerkin
  attn_activation: gelu
  feat_extract_type: None
  xavier_init: 0.01
  diagonal_weight: 0.01
  symmetric_init: False
  layer_norm: True
  attn_norm: False
  norm_eps: 0.00001
  batch_norm: False
  return_attn_weight: False
  return_latent: False
  decoder_type: ifft2
  last_activation: True
  freq_dim: 32
  num_regressor_layers: 2
  regressor_activation: gelu
  fourier_modes: 32
  spacial_dim: 2
  spacial_fc: False
  dropout: 0.0
  encoder_dropout: 0.0
  decoder_dropout: 0.0
  ffn_dropout: 0.0
  upsample_mode: interp
  downsample_mode: interp
